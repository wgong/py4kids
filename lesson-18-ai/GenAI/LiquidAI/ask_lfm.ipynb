{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liquid AI LFM2.5 Interactive Demo\n",
    "\n",
    "This notebook demonstrates how to use the Liquid AI LFM2.5-1.2B-Instruct model with an interactive widget interface."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Install required packages if not already installed\n",
    "!pip install ipywidgets transformers>=4.46.0 accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: LiquidAI/LFM2.5-1.2B-Instruct\n",
      "This may take a few minutes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd8316586d94de1a58990e0db008c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"LiquidAI/LFM2.5-1.2B-Instruct\"\n",
    "\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Define a BitsAndBytesConfig for 4-bit quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",  # or \"fp4\"\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load model with quantization\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "\n",
    "print(f\"Model loaded successfully!\")\n",
    "print(f\"Device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question: str, max_new_tokens: int = 256) -> str:\n",
    "    \"\"\"\n",
    "    Generate an answer using the LFM2.5 model\n",
    "    \"\"\"\n",
    "    # Create the prompt with instruction formatting\n",
    "    prompt = (\n",
    "        \"You are a friendly teacher.\\n\"\n",
    "        \"Explain your answer step by step in simple language.\\n\\n\"\n",
    "        f\"Question:\\n{question}\\n\\nAnswer:\\n\"\n",
    "    )\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Generate response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.4,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # Decode and extract only the generated part\n",
    "    full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    answer = full_text[len(prompt):].strip()\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc6f8f3367b412bbbf3c7b97dc3bbf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h2>ü§ñ Ask LFM2.5 Anything!</h2>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a74ab7a7d74b869534f8b744680a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Explain step by step: What is the difference between speed and velocity?', description='Questi‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8668662db4e34f12bf184b1fa1c55fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=256, description='Max tokens:', max=512, min=50, step=50, style=SliderStyle(description_width=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5394fd47b7f845fb9a5bf9c471c2c5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='success', description='Ask LFM2.5', layout=Layout(width='200px'), style=Bu‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb97b19c73547f78cf2929c864c83a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Answer:', layout=Layout(height='300px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create interactive widgets\n",
    "question_box = widgets.Textarea(\n",
    "    value=\"Explain step by step: What is the difference between speed and velocity?\",\n",
    "    placeholder=\"Ask LFM2.5 a question (math, code, or explanation)...\",\n",
    "    description=\"Question:\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"120px\")\n",
    ")\n",
    "\n",
    "max_tokens_slider = widgets.IntSlider(\n",
    "    value=256,\n",
    "    min=50,\n",
    "    max=512,\n",
    "    step=50,\n",
    "    description=\"Max tokens:\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "answer_box = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    description=\"Answer:\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"300px\")\n",
    ")\n",
    "\n",
    "button = widgets.Button(\n",
    "    description=\"Ask LFM2.5\",\n",
    "    button_style=\"success\",\n",
    "    layout=widgets.Layout(width=\"200px\")\n",
    ")\n",
    "\n",
    "status_label = widgets.HTML(value=\"Ready to answer questions!\")\n",
    "\n",
    "# Button click handler\n",
    "def on_click(b):\n",
    "    if not question_box.value.strip():\n",
    "        status_label.value = \"<span style='color: red;'>Please enter a question!</span>\"\n",
    "        return\n",
    "    \n",
    "    # Update status\n",
    "    status_label.value = \"<span style='color: blue;'>ü§î Thinking...</span>\"\n",
    "    answer_box.value = \"Generating answer...\"\n",
    "    \n",
    "    try:\n",
    "        # Generate answer\n",
    "        answer = generate_answer(question_box.value, max_tokens_slider.value)\n",
    "        answer_box.value = answer\n",
    "        status_label.value = \"<span style='color: green;'>‚úÖ Answer generated!</span>\"\n",
    "    except Exception as e:\n",
    "        answer_box.value = f\"Error generating answer: {str(e)}\"\n",
    "        status_label.value = \"<span style='color: red;'>‚ùå Error occurred!</span>\"\n",
    "\n",
    "button.on_click(on_click)\n",
    "\n",
    "# Display the interface\n",
    "display(\n",
    "    widgets.HTML(\"<h2>ü§ñ Ask LFM2.5 Anything!</h2>\"),\n",
    "    question_box,\n",
    "    max_tokens_slider,\n",
    "    widgets.HBox([button, status_label]),\n",
    "    answer_box\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Questions to Try:\n",
    "\n",
    "- Why is the sky blue?\n",
    "- Explain the Pythagorean theorem step by step\n",
    "- What is the difference between speed and velocity?\n",
    "- How do Python lists work?\n",
    "- Explain photosynthesis in simple terms\n",
    "- What is machine learning?\n",
    "- How do you solve a quadratic equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with question: Why is the sky blue?\n",
      "\n",
      "Answer:\n",
      "Let's think about this step by step.\n",
      "\n",
      "1. First, we need to understand what color the sky appears to be.\n",
      "- When the sun is shining, the sky looks blue.\n",
      "\n",
      "2. Now, let's think about how light interacts with the atmosphere.\n",
      "- Sunlight is made up of many different colors, but most of it passes through the atmosphere.\n",
      "\n",
      "3. What happens when sunlight enters the atmosphere?\n",
      "- The blue part of sunlight scatters more than the other colors.\n",
      "\n",
      "4. Why does blue scatter more?\n",
      "- Blue light has a shorter wavelength and bounces off particles in the air more than other colors.\n",
      "\n",
      "5. What happens because of this scattering?\n",
      "- The scattered blue light spreads out in all directions, making the sky appear blue to us.\n",
      "\n",
      "6. So, the blue color we see comes from this scattering process.\n",
      "\n",
      "Putting it all together:\n",
      "The sky is blue because the blue part of sunlight scatters more in the atmosphere, and we see that scattered blue light.\n",
      "\n",
      "Would you like to ask more questions about this?\n",
      "\n",
      "Answer: \n",
      "The sky appears blue because the blue light from the sun scatters more when it enters the Earth's atmosphere. This scattering makes the blue light spread out and reach our eyes,\n"
     ]
    }
   ],
   "source": [
    "# Quick test - run this cell to test the model directly\n",
    "test_question = \"Why is the sky blue?\"\n",
    "print(f\"Testing with question: {test_question}\\n\")\n",
    "print(\"Answer:\")\n",
    "print(generate_answer(test_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liquidai",
   "language": "python",
   "name": "liquidai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
