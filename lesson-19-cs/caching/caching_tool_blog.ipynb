{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading Time for Space: Adding TTL Caching to Your Python Functions\n",
    "\n",
    "When optimizing algorithms, we often face the classic time vs. space complexity trade-off. Sometimes, it makes sense to use more memory to achieve faster execution times, especially when dealing with repeated operations. In this notebook, we'll explore how to add Time-To-Live (TTL) caching to a Python function that trades time for space complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "Let's start with a simple hash search function that converts an array into a dictionary for O(1) lookups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_search(array, item):\n",
    "    if array is None or len(array) < 1: \n",
    "        return None\n",
    "    m = {val : n for n, val in enumerate(array)}\n",
    "    return m[item] if item in m else None\n",
    "\n",
    "# Test the basic function\n",
    "test_array = [1, 2, 3, 4, 5]\n",
    "result = hash_search(test_array, 3)\n",
    "print(f\"Index of 3 in {test_array}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function trades time for space by creating a hash map (`m`) from the input array. While this gives us fast lookups, we rebuild the hash map on every function call, even for the same array. If we're searching the same arrays repeatedly, we're doing unnecessary work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Solution: TTL Caching\n",
    "\n",
    "We can cache the hash map with a Time-To-Live (TTL) mechanism, so subsequent calls with the same array reuse the cached dictionary until it expires.\n",
    "\n",
    "### Functional Approach with Global Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required package if not already installed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "install_package(\"cachetools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cachetools import TTLCache\n",
    "import hashlib\n",
    "import pickle\n",
    "\n",
    "# Global cache with TTL (100 entries max, 5-minute expiration)\n",
    "_hash_cache = TTLCache(maxsize=100, ttl=300)\n",
    "\n",
    "def hash_search_cached(array, item):\n",
    "    if array is None or len(array) < 1: \n",
    "        return None\n",
    "    \n",
    "    # Create a robust cache key\n",
    "    try:\n",
    "        # Try built-in hash first (fastest)\n",
    "        array_key = hash(tuple(array))\n",
    "    except TypeError:\n",
    "        # Fallback for unhashable elements (lists, dicts, etc.)\n",
    "        array_bytes = pickle.dumps(array)\n",
    "        array_key = hashlib.md5(array_bytes).hexdigest()\n",
    "    \n",
    "    # Check cache first\n",
    "    if array_key not in _hash_cache:\n",
    "        print(f\"Cache MISS - creating hash map for array of length {len(array)}\")\n",
    "        # Cache miss: create and store the hash map\n",
    "        _hash_cache[array_key] = {val: n for n, val in enumerate(array)}\n",
    "    else:\n",
    "        print(f\"Cache HIT - reusing hash map for array of length {len(array)}\")\n",
    "    \n",
    "    # Use cached hash map\n",
    "    m = _hash_cache[array_key]\n",
    "    return m[item] if item in m else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the cached version\n",
    "test_array = [1, 2, 3, 4, 5] * 1000  # Large array\n",
    "\n",
    "print(\"First call (should be cache miss):\")\n",
    "result1 = hash_search_cached(test_array, 3)\n",
    "print(f\"Result: {result1}\")\n",
    "\n",
    "print(\"\\nSecond call (should be cache hit):\")\n",
    "result2 = hash_search_cached(test_array, 4)\n",
    "print(f\"Result: {result2}\")\n",
    "\n",
    "print(f\"\\nCache size: {len(_hash_cache)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class-Based Approach: Better for Apps and Libraries\n",
    "\n",
    "For building applications and libraries, a class-based approach provides better encapsulation, flexibility, and API design:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashSearcher:\n",
    "    def __init__(self, ttl_seconds=300, maxsize=100):\n",
    "        self._cache = TTLCache(maxsize=maxsize, ttl=ttl_seconds)\n",
    "    \n",
    "    def search(self, array, item):\n",
    "        if array is None or len(array) < 1:\n",
    "            return None\n",
    "        \n",
    "        # Create a robust cache key\n",
    "        try:\n",
    "            array_key = hash(tuple(array))\n",
    "        except TypeError:\n",
    "            array_bytes = pickle.dumps(array)\n",
    "            array_key = hashlib.md5(array_bytes).hexdigest()\n",
    "        \n",
    "        # Check cache first\n",
    "        if array_key not in self._cache:\n",
    "            print(f\"Cache MISS - creating hash map\")\n",
    "            self._cache[array_key] = {val: n for n, val in enumerate(array)}\n",
    "        else:\n",
    "            print(f\"Cache HIT - reusing hash map\")\n",
    "        \n",
    "        m = self._cache[array_key]\n",
    "        return m[item] if item in m else None\n",
    "    \n",
    "    def clear_cache(self):\n",
    "        \"\"\"Manually clear the cache if needed\"\"\"\n",
    "        self._cache.clear()\n",
    "    \n",
    "    def cache_info(self):\n",
    "        \"\"\"Get cache statistics\"\"\"\n",
    "        return {\n",
    "            'size': len(self._cache),\n",
    "            'maxsize': self._cache.maxsize,\n",
    "            'ttl': self._cache.ttl\n",
    "        }\n",
    "    \n",
    "    def contains_array(self, array):\n",
    "        \"\"\"Check if array is already cached\"\"\"\n",
    "        try:\n",
    "            array_key = hash(tuple(array))\n",
    "        except TypeError:\n",
    "            array_bytes = pickle.dumps(array)\n",
    "            array_key = hashlib.md5(array_bytes).hexdigest()\n",
    "        return array_key in self._cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the class-based approach\n",
    "searcher = HashSearcher(ttl_seconds=60, maxsize=50)\n",
    "\n",
    "test_array = [10, 20, 30, 40, 50]\n",
    "print(\"Testing HashSearcher:\")\n",
    "print(f\"Search for 30: {searcher.search(test_array, 30)}\")\n",
    "print(f\"Search for 40: {searcher.search(test_array, 40)}\")\n",
    "print(f\"Cache info: {searcher.cache_info()}\")\n",
    "print(f\"Array cached: {searcher.contains_array(test_array)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Class-Based Is Better for Production\n",
    "\n",
    "#### 1. Multiple Cache Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different strategies for different use cases\n",
    "fast_searcher = HashSearcher(ttl_seconds=60, maxsize=50)    # Quick operations\n",
    "persistent_searcher = HashSearcher(ttl_seconds=3600, maxsize=200)  # Long-lived data\n",
    "user_searcher = HashSearcher(ttl_seconds=1800, maxsize=10)  # Per-user cache\n",
    "\n",
    "print(\"Multiple searchers created with different configurations:\")\n",
    "print(f\"Fast: {fast_searcher.cache_info()}\")\n",
    "print(f\"Persistent: {persistent_searcher.cache_info()}\")\n",
    "print(f\"User: {user_searcher.cache_info()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Enhanced API with Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedHashSearcher(HashSearcher):\n",
    "    def __init__(self, ttl_seconds=300, maxsize=100, enable_stats=True):\n",
    "        super().__init__(ttl_seconds, maxsize)\n",
    "        self.enable_stats = enable_stats\n",
    "        self.hit_count = 0\n",
    "        self.miss_count = 0\n",
    "    \n",
    "    def search(self, array, item):\n",
    "        if array is None or len(array) < 1:\n",
    "            return None\n",
    "        \n",
    "        array_key = self._create_key(array)\n",
    "        \n",
    "        if array_key in self._cache:\n",
    "            if self.enable_stats:\n",
    "                self.hit_count += 1\n",
    "                print(f\"Cache HIT (total hits: {self.hit_count})\")\n",
    "        else:\n",
    "            if self.enable_stats:\n",
    "                self.miss_count += 1\n",
    "                print(f\"Cache MISS (total misses: {self.miss_count})\")\n",
    "        \n",
    "        return super().search(array, item)\n",
    "    \n",
    "    def _create_key(self, array):\n",
    "        try:\n",
    "            return hash(tuple(array))\n",
    "        except TypeError:\n",
    "            array_bytes = pickle.dumps(array)\n",
    "            return hashlib.md5(array_bytes).hexdigest()\n",
    "    \n",
    "    def get_hit_ratio(self):\n",
    "        total = self.hit_count + self.miss_count\n",
    "        return self.hit_count / total if total > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the advanced searcher\n",
    "advanced_searcher = AdvancedHashSearcher(ttl_seconds=300)\n",
    "test_array = [1, 2, 3, 4, 5]\n",
    "\n",
    "print(\"Testing AdvancedHashSearcher:\")\n",
    "for i in range(5):\n",
    "    result = advanced_searcher.search(test_array, 3)\n",
    "    \n",
    "print(f\"\\nFinal hit ratio: {advanced_searcher.get_hit_ratio():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Benefits\n",
    "\n",
    "Let's see the improvement with a performance test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Large array for testing\n",
    "large_array = list(range(10000))\n",
    "\n",
    "# Without caching - rebuilds hash map every time\n",
    "print(\"Testing without caching...\")\n",
    "start = time.time()\n",
    "for _ in range(100):  # Reduced iterations for notebook\n",
    "    hash_search(large_array, 5000)\n",
    "no_cache_time = time.time() - start\n",
    "print(f\"Without caching: {no_cache_time:.3f}s\")\n",
    "\n",
    "# With caching - builds hash map once, reuses 99 times\n",
    "print(\"\\nTesting with caching...\")\n",
    "searcher = HashSearcher()\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    searcher.search(large_array, 5000)\n",
    "cache_time = time.time() - start\n",
    "print(f\"With caching: {cache_time:.3f}s\")\n",
    "\n",
    "print(f\"\\nSpeedup: {no_cache_time/cache_time:.1f}x faster with caching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library-Friendly Design\n",
    "\n",
    "The class-based approach is perfect for building reusable libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSearchLibrary:\n",
    "    def __init__(self):\n",
    "        self.hash_searcher = HashSearcher(ttl_seconds=600)\n",
    "        # Could add other search strategies here\n",
    "    \n",
    "    def find_in_array(self, array, item, method='auto'):\n",
    "        \"\"\"\n",
    "        Find item in array using the best search method.\n",
    "        \n",
    "        Args:\n",
    "            array: List to search in\n",
    "            item: Item to find\n",
    "            method: 'hash', 'linear', or 'auto'\n",
    "        \n",
    "        Returns:\n",
    "            Index of item or None if not found\n",
    "        \"\"\"\n",
    "        if method == 'hash' or (method == 'auto' and len(array) > 100):\n",
    "            return self.hash_searcher.search(array, item)\n",
    "        else:\n",
    "            # Fallback to linear search for small arrays\n",
    "            try:\n",
    "                return array.index(item)\n",
    "            except ValueError:\n",
    "                return None\n",
    "    \n",
    "    def get_cache_stats(self):\n",
    "        \"\"\"Get performance statistics\"\"\"\n",
    "        return self.hash_searcher.cache_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the library\n",
    "search_lib = DataSearchLibrary()\n",
    "\n",
    "# Test with small array (should use linear search)\n",
    "small_array = [1, 2, 3, 4, 5]\n",
    "print(f\"Small array search (auto): {search_lib.find_in_array(small_array, 3)}\")\n",
    "\n",
    "# Test with large array (should use hash search)\n",
    "large_array = list(range(1000))\n",
    "print(f\"Large array search (auto): {search_lib.find_in_array(large_array, 500)}\")\n",
    "print(f\"Cache stats: {search_lib.get_cache_stats()}\")\n",
    "\n",
    "# Force hash method on small array\n",
    "print(f\"Small array with hash method: {search_lib.find_in_array(small_array, 3, 'hash')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn More About Cachetools\n",
    "\n",
    "The `cachetools` library provides several powerful caching strategies beyond the TTL approach we used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cachetools import (\n",
    "    LRUCache,    # Least Recently Used\n",
    "    TTLCache,    # Time To Live  \n",
    "    TLRUCache,   # Time-aware LRU\n",
    "    LFUCache,    # Least Frequently Used\n",
    "    RRCache,     # Random Replacement\n",
    "    Cache        # Basic FIFO cache\n",
    ")\n",
    "\n",
    "# Demonstrate LRU vs TTL\n",
    "print(\"=== LRU Cache Demo ===\")\n",
    "lru_cache = LRUCache(maxsize=3)\n",
    "\n",
    "lru_cache['A'] = 1  \n",
    "lru_cache['B'] = 2  \n",
    "lru_cache['C'] = 3  \n",
    "print(f\"After adding A, B, C: {dict(lru_cache)}\")\n",
    "\n",
    "# Access A (moves it to \"most recent\")\n",
    "value = lru_cache['A']  \n",
    "print(f\"After accessing A: {dict(lru_cache)}\")\n",
    "\n",
    "lru_cache['D'] = 4  # Evicts B (least recently used)\n",
    "print(f\"After adding D: {dict(lru_cache)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== TTL Cache Demo ===\")\n",
    "ttl_cache = TTLCache(maxsize=100, ttl=2)  # 2-second expiration\n",
    "\n",
    "ttl_cache['data'] = 'fresh_data'\n",
    "print(f\"Immediately after adding: {'data' in ttl_cache}\")\n",
    "\n",
    "time.sleep(1)\n",
    "print(f\"After 1 second: {'data' in ttl_cache}\")\n",
    "\n",
    "time.sleep(2)\n",
    "print(f\"After 3 seconds total: {'data' in ttl_cache}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Class-based design** provides better encapsulation and flexibility for apps and libraries\n",
    "2. **TTL caching** dramatically improves performance for repeated operations on the same data\n",
    "3. **Robust key generation** prevents cache collisions and handles complex data types\n",
    "4. **Configurable cache parameters** allow optimization for different use cases\n",
    "5. **Additional methods** like `cache_info()` and `clear_cache()` provide operational control\n",
    "6. **Thread safety** can be added when needed without changing the core API\n",
    "\n",
    "By transforming our simple hash search function into a robust, cacheable class, we've created a reusable component that's perfect for applications and libraries. The class-based approach provides all the performance benefits of caching while maintaining clean, professional APIs that are easy to test, extend, and integrate into larger systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}